---
title: "STAT 345 Final Project - Over and Over and Over and Over"
author: "Matt Nowell, Sam Schuster, James Spalding, Ben Bronoski"
output: html_document
---

Expected Submission: You will generate a well-written R Markdown report that addresses the following prompts. This R Markdown report should source your analysis code and only display top-level, abstracted code _if/when appropriate_. Choices made during the analysis project should be described and justified in the report. 


Advice for getting started:

- Start a conversation chain with your group members. Email is a great place to start, but other options exist (texting, social media platforms, etc.). Set some reasonable expectations for how and when you plan to respond to conversations. It is likely going to be unacceptable to only respond once per week, for example, but also likely unacceptable to expect a response within the hour. Have an honest conversation with your group members about this issue.
- Start the project from a "top-down design" perspective. So, determine what the major steps of the process are, and determine what the inputs and outputs are for each of those steps (the output of step 1 will likely be the input for step 2, for example). This step is much like writing an outline for a paper before you start to write the paper itself, only much more valuable in a group setting. 
- Once you have a sense of the big picture (the outline), determine some "due dates" for each step of the process. Work backwards from the final submission date, giving yourselves time to work on each of the parts as needed. Given the top-down design, you should be able to "divide and conquer" -- working on parts of the project that depend on earlier steps.
- Decide how you plan to share code with each other. Using Git and GitHub is a really good choice here. If not, perhaps some form of shared directory online. In a worst-case scenario, email could also work. 
- Be prepared to give Dr. Baumann (at least) weekly updates on your progress. Some of this can be done via email, but discuss with your group about times you are each available to meet online as well (in an office-hour-like setting). Feel free to request meetings with Dr. Baumann to get help.

**General advice:** Get started early. If you wait to the last minute, it will not go well. For this project, you may find yourself spending a reasonable amount of time _searching_ for help.

1. Your first task is to create a list of top songs, dating back to 1958 (when Billboard introduced it's Hot 100 yearly chart). You may want to start with just the yearly top song, but your work should be general enough to account for multiple songs per year. You may narrow your search to a particular genre if you like. You may use any website that provides this information, though you may try to find one that makes part 2 as simple as possible.

2. For the top songs in part 1, gather some basic information: artist, title, year, genre (if appropriate), length, and other variables you think might be informative (sales figures, etc.).

3. Find a lyric hosting service (such as www.azlyrics.com or www.songlyrics.com, though these aren't the only options) that provides full lyrics to songs. Ideally, the URLs for these songs follow a reproducible pattern. Write a function that can automatically capture these song lyrics for your top songs from part 1, and then gather the lyrics. Do your best to keep this function general, but you may need to write code for specific instances.

4. Create two measures of song repetitiveness. Write a function (or two) to measure song repetitiveness, and apply it to each of the songs from part 1. Suggestions for "repetitiveness" include (but are definitely not limited to): "Do songs repeat the same phrase frequently?" and "Do songs repeat their song title frequently"

5. Have songs become more repetitive over time? Summarize and visualize your repetitive measures from part 4. 

6. (If possible) Extend your work to more songs! Consider more questions, like "Does genre matter?".

hi hello
Packages:
```{r}
library(tidyverse)
library(rvest)
```


Ugly data collection:
```{r}
url = "https://en.wikipedia.org/wiki/Billboard_year-end_top_50_singles_of_1958"
h = read_html(url)
table_1958 = h %>% html_table
table_1958 = data.frame(table_1958[[1]])
year = rep(1958, each = 51)
new_table = cbind(table_1958, year)
table_1958 = setNames(object = final_table, c("No.", "Title", "Artist", "Year"))
table_1958 = table_1958[1:20,]

url2 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1959"
h2 = read_html(url2)
table_1959 = h2 %>% html_table
table_1959 = data.frame(table_1959[[1]])
year2 = rep(1959, each = 100)
new_table2 = cbind(table_1959, year2)
table_1959 = setNames(object = new_table2, c("No.", "Title", "Artist", "Year"))
table_1959 = table_1959[1:20,]

url3 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1960"
h3 = read_html(url3)
table_1960 = h3 %>% html_table
table_1960 = data.frame(table_1960[[1]])
year3 = rep(1960, each = 100)
new_table3 = cbind(table_1960, year3)
table_1960 = setNames(object = new_table3, c("No.", "Title", "Artist", "Year"))
table_1960 = table_1960[1:20,]

url4 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1961"
h4 = read_html(url4)
table_1961 = h4 %>% html_table
table_1961 = data.frame(table_1961[[1]])
year4 = rep(1961, each = 100)
new_table4 = cbind(table_1961, year4)
table_1961 = setNames(object = new_table4, c("No.", "Title", "Artist", "Year"))
table_1961 = table_1961[1:20,]

url5 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1962"
h5 = read_html(url5)
table_1962 = h5 %>% html_table
table_1962 = data.frame(table_1962[[1]])
year5 = rep(1962, each = 100)
new_table5 = cbind(table_1962, year5)
table_1962 = setNames(object = new_table5, c("No.", "Title", "Artist", "Year"))
table_1962 = table_1962[1:20,]

url6 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1963"
h6 = read_html(url6)
table_1963 = h6 %>% html_table
table_1963 = data.frame(table_1963[[1]])
year6 = rep(1963, each = 100)
new_table6 = cbind(table_1963, year6)
table_1963 = setNames(object = new_table6, c("No.", "Title", "Artist", "Year"))
table_1963 = table_1963[1:20,]

url7 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1964"
h7 = read_html(url7)
table_1964 = h7 %>% html_table
table_1964 = data.frame(table_1964[[1]])
year7 = rep(1964, each = 100)
new_table7 = cbind(table_1964, year7)
table_1964 = setNames(object = new_table7, c("No.", "Title", "Artist", "Year"))
table_1964 = table_1964[1:20,]

url8 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1965"
h8 = read_html(url8)
table_1965 = h8 %>% html_table
table_1965 = data.frame(table_1965[[1]])
year8 = rep(1965, each = 100)
new_table8 = cbind(table_1965, year8)
table_1965 = setNames(object = new_table8, c("No.", "Title", "Artist", "Year"))
table_1965 = table_1965[1:20,]

url9 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1966"
h9 = read_html(url9)
table_1966 = h9 %>% html_table
table_1966 = data.frame(table_1966[[1]])
year9 = rep(1966, each = 100)
new_table9 = cbind(table_1966, year9)
table_1966 = setNames(object = new_table9, c("No.", "Title", "Artist", "Year"))
table_1966 = table_1966[1:20,]

url10 = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1967"
h10 = read_html(url10)
table_1967 = h10 %>% html_table
table_1967 = data.frame(table_1967[[1]])
year10 = rep(1967, each = 100)
new_table10 = cbind(table_1967, year10)
table_1967 = setNames(object = new_table10, c("No.", "Title", "Artist", "Year"))
table_1967 = table_1967[1:20,]

final_table = rbind.data.frame(table_1958, table_1959, table_1960, table_1961, table_1962, table_1963, table_1964, table_1965, table_1966, table_1967)
```

